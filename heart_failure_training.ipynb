{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart Failure Prediction Model Training\n",
    "\n",
    "This notebook demonstrates how to train a machine‑learning model to predict heart failure using a CSV dataset.\n",
    "We will use **scikit‑learn** and avoid any GPU‑specific libraries.\n",
    "\n",
    "**Goals**:\n",
    "- Load and explore the dataset\n",
    "- Preprocess features (handle missing values, encode categoricals)\n",
    "- Split data into train/test sets\n",
    "- Train several models and improve accuracy with simple hyper‑parameter tuning\n",
    "- Evaluate the final model\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the CSV dataset\n",
    "Replace `your_dataset.csv` with the actual filename located in the repository."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Path to the CSV file – adjust if needed\n",
    "csv_path = 'data/heart_failure.csv'  # example path\n",
    "df = pd.read_csv(csv_path)\n",
    "df.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick data inspection"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print('Shape:', df.shape)\n",
    "print('Columns:', df.columns.tolist())\n",
    "print(df.isnull().sum())\n",
    "df.describe()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define target and features\n",
    "Assuming the target column is named `target` (adjust accordingly)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "target_col = 'target'  # change to actual label column name\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess: numeric scaling + categorical encoding\n",
    "Identify numeric and categorical columns automatically."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n        ('scaler', StandardScaler())\n    ])\n",
    "categorical_transformer = Pipeline(steps=[\n        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n    ])\n",
    "\n",
    "preprocess = ColumnTransformer(\n        transformers=[\n            ('num', numeric_transformer, numeric_features),\n            ('cat', categorical_transformer, categorical_features)\n        ])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train‑test split"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42, stratify=y)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model – Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "rf_clf = Pipeline(steps=[\n        ('preprocess', preprocess),\n        ('classifier', RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=1))\n    ])\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple hyper‑parameter tuning with GridSearchCV (still CPU‑only)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "param_grid = {\n        'classifier__n_estimators': [100, 200, 300],\n        'classifier__max_depth': [None, 10, 20],\n        'classifier__min_samples_split': [2, 5, 10]\n    }\n",
    "grid_search = GridSearchCV(rf_clf, param_grid, cv=5, scoring='accuracy', n_jobs=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print('Best parameters:', grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "print('Tuned Accuracy:', accuracy_score(y_test, y_pred_best))\n",
    "print(classification_report(y_test, y_pred_best))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Try Gradient Boosting for potentially higher accuracy"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "gb_clf = Pipeline(steps=[\n        ('preprocess', preprocess),\n        ('classifier', GradientBoostingClassifier(random_state=42))\n    ])\n",
    "gb_clf.fit(X_train, y_train)\n",
    "y_pred_gb = gb_clf.predict(X_test)\n",
    "print('GB Accuracy:', accuracy_score(y_test, y_pred_gb))\n",
    "print(classification_report(y_test, y_pred_gb))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Confusion Matrix (for the best model)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Tuned Random Forest')\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10"}},
 "nbformat": 4,
 "nbformat_minor": 5
}
